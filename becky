#!/bin/bash

CONFIG_PATH="./becky.conf"

if [ -f "./development.becky.conf" ]; then
	CONFIG_PATH="./development.becky.conf"
fi

###############################################################################
# Declare some printing functions for prettier output.
###############################################################################

RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color.

print_error() {
	printf "${RED}[ERROR]${NC} $*\n"
}
print_info() {
	printf "${GREEN}[INFO]${NC} $*\n"
}
print_warn() {
	printf "${YELLOW}[WARN]${NC} $*\n"
}

pretty_time() {
	((h = ${1} / 3600))
	((m = (${1} % 3600) / 60))
	((s = ${1} % 60))
	printf "%02d:%02d:%02d\n" $h $m $s
}

###############################################################################
# Cleanup after exit.
###############################################################################

cleanup() {
	# Remove MySQL credentials.
	rm -f "$HOME/.becky.mylogin.cnf"
	# Move the original AWS config files back.
	if [ -f ~/.aws/config.becky.backup ]; then
		mv ~/.aws/config.becky.backup ~/.aws/config
	fi
	if [ -f ~/.aws/credentials.becky.backup ]; then
		mv ~/.aws/credentials.becky.backup ~/.aws/credentials
	fi
}

trap cleanup EXIT

###############################################################################
# Imports.
###############################################################################

if ! [ -f "${CONFIG_PATH}" ]; then
	print_error "Config file not found: ${CONFIG_PATH}"
	exit 1
fi

. ${CONFIG_PATH}

###############################################################################
# Ensure that dependencies are installed.
###############################################################################

DEPENDENCIES=(
	"aws"
	"tar"
	"gzip"
	"date"
	"cat"
	"tr"
)

for dep in ${DEPENDENCIES[*]}; do
	if ! command -v $dep &>/dev/null; then
		print_error "Missing dependency: $dep"
		exit 1
	fi
done

###############################################################################
# Ensure required variable in the becky.conf have been set.
###############################################################################

if [ -z $BECKY_S3_BUCKET ]; then
	print_error "You have not set which S3 bucket to use: BECKY_S3_BUCKET"
	print_info "Set the variable in ${CONFIG_PATH}"
	exit 1
fi
if [ -z $BECKY_AWS_REGION ]; then
	print_error "You have not set the AWS region: BECKY_AWS_REGION"
	print_info "Set the variable in ${CONFIG_PATH}"
	exit 1
fi
if [ -z $BECKY_ACCESS_KEY_ID ]; then
	print_error "You have not set the access key id: BECKY_ACCESS_KEY_ID"
	print_info "Set the variable in ${CONFIG_PATH}"
	exit 1
fi
if [ -z $BECKY_SECRET_ACCESS_KEY ]; then
	print_error "You have not set the secret access key: BECKY_SECRET_ACCESS_KEY"
	print_info "Set the variable in ${CONFIG_PATH}"
	exit 1
fi

###############################################################################
# Create AWS credentials and config.
###############################################################################

mkdir -p ~/.aws

if [ -f ~/.aws/config ]; then
	cp ~/.aws/config ~/.aws/config.becky.backup
fi
if [ -f ~/.aws/credentials ]; then
	cp ~/.aws/credentials ~/.aws/credentials.becky.backup
fi

cat <<EOF >$HOME/.aws/config
[default]
region = $BECKY_AWS_REGION
s3 =
    multipart_treshold = $BECKY_UPLOAD_CHUNKSIZE
    multipart_chunksize = $BECKY_UPLOAD_CHUNKSIZE
    max_bandwidth = $BECKY_MAX_BANDWIDTH
EOF

cat <<EOF >$HOME/.aws/credentials
[default]
aws_access_key_id = $BECKY_ACCESS_KEY_ID
aws_secret_access_key = $BECKY_SECRET_ACCESS_KEY
EOF

chmod 600 ~/.aws/config
chmod 600 ~/.aws/credentials

###############################################################################
# Create MySQL defaults file to use the credentials from there.
###############################################################################

cat <<EOF >$HOME/.becky.mylogin.cnf
[client]
user="$BECKY_MYSQL_USERNAME"
password="$BECKY_MYSQL_PASSWORD"
EOF

###############################################################################
# Print backup start time.
###############################################################################

BACKUP_START_TIME=$(date +%s)
print_info "Backup started at: $(date -d @${BACKUP_START_TIME} -u -Is)"

###############################################################################
# Backup databases.
###############################################################################

if [ -z ${BECKY_MYSQL_DATABASES} ]; then
	print_warn "Skipping MySQL database backup because BECKY_MYSQL_DATABASES is not set..."
else
	print_info "Backing up databases..."

	DATABASES=$(echo $BECKY_MYSQL_DATABASES | tr "," "\n")
	for D in $DATABASES; do
		FILE_NAME=${BECKY_PREFIX}${D}.tar.gz
		S3_PATH="s3://${BECKY_S3_BUCKET}${BECKY_DATABASES_DIRECTORY}/${FILE_NAME}"

		print_info "Creating archive: ${S3_PATH}"
		FILE_UPLOAD_START_TIME=$(date +%s)

		mysqldump --defaults-file="$HOME/.becky.mylogin.cnf" ${D} |
			gzip -9 |
			aws s3 cp - ${S3_PATH}

		FILE_UPLOAD_STOP_TIME=$(date +%s)
		FILE_UPLOAD_TOTAL_TIME=$((FILE_UPLOAD_STOP_TIME - FILE_UPLOAD_START_TIME))
		print_info "Archive creation completed in (HH:MM:SS): $(pretty_time ${FILE_UPLOAD_TOTAL_TIME})"
	done
fi

###############################################################################
# Backup files and folders.
###############################################################################

if [ -z ${BECKY_SOURCES} ]; then
	print_warn "Skipping file backup because BECKY_SOURCES is not set..."
else
	print_info "Archiving files and folders..."

	FOLDERS=$(echo $BECKY_SOURCES | tr "," "\n")
	for F in $FOLDERS; do
		if ! [ -e "${F}" ]; then
			print_error "File/directory does not exist: ${F}"
			continue
		fi
		if [ -S "${F}" ]; then
			print_error "You can't backup a socket: ${F}"
			continue
		fi
		if ! [ -r "${F}" ]; then
			print_error "No read permissions for: ${F}"
			continue
		fi

		# Strip the leading slash.
		if [ ${F:0:1} = '/' ]; then
			F=${F:1}
		else
			print_error "Not an absolute path: ${F}"
			exit 1
		fi

		# Replace slashes with underscores.
		FILE_NAME=${BECKY_PREFIX}${F//\//_}.tar.gz

		S3_PATH="s3://${BECKY_S3_BUCKET}${BECKY_FILES_DIRECTORY}/${FILE_NAME}"

		print_info "Creating archive: ${S3_PATH}"
		FILE_UPLOAD_START_TIME=$(date +%s)

		# Calculate approximate size of the archive so we can pass
		# the --expected-size argument for archives larger than 50GB.
		# See https://awscli.amazonaws.com/v2/documentation/api/latest/reference/s3/cp.html
		ESTIMATED_SIZE=$(tar -C '/' -cpzf - "${F}" | wc -c)
		EXPECTED_SIZE=""
		if [ $ESTIMATED_SIZE -gt 50000000000 ]; then
			EXPECTED_SIZE="--expected-size ${ESTIMATED_SIZE}"
		fi

		tar -C '/' -cpf - ${F} |
			gzip -9 |
			aws s3 cp - \
				${S3_PATH}} \
				$EXPECTED_SIZE

		FILE_UPLOAD_STOP_TIME=$(date +%s)
		FILE_UPLOAD_TOTAL_TIME=$((FILE_UPLOAD_STOP_TIME - FILE_UPLOAD_START_TIME))
		print_info "Archive creation completed in (HH:MM:SS): $(pretty_time ${FILE_UPLOAD_TOTAL_TIME})"
	done
fi

###############################################################################
# Print backup stop time.
###############################################################################

BACKUP_STOP_TIME=$(date +%s)
print_info "Backup stopped at: $(date -d @${BACKUP_STOP_TIME} -u -Is)"
BACKUP_TOTAL_TIME=$((BACKUP_STOP_TIME - BACKUP_START_TIME))
print_info "Backup total time (HH:MM:SS): $(pretty_time ${BACKUP_TOTAL_TIME})"
